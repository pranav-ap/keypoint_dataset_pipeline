{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/stud/ath/ath_ws/keypoint_dataset_pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import config\n",
    "from utils import logger\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_hdf5_structure(reader):\n",
    "    def print_group(name, obj):\n",
    "        if isinstance(obj, h5py.Group):\n",
    "            print(f\"Group: {name}\")\n",
    "            \n",
    "    reader._file.visititems(print_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatsReader:\n",
    "    def __init__(self, train=False):\n",
    "        # filepath = f'{config.paths[config.task.name].output}/data.hdf5'\n",
    "        filepath = '/home/stud/ath/ath_ws/keypoint_dataset_pipeline/output/output_all/basalt/monado_slam/MGO08_mapping_hard/data.hdf5'\n",
    "        self._file = h5py.File(filepath, 'r')\n",
    "        \n",
    "        self._init_groups_read_mode()\n",
    "\n",
    "    def _init_groups_read_mode(self):\n",
    "        self._detector = self._file[f'{config.task.cam}/detector']\n",
    "        self._matcher = self._file[f'{config.task.cam}/matcher']\n",
    "        self._filter = self._file[f'{config.task.cam}/filter']\n",
    "        self._matches = self._file[f'{config.task.cam}/matches']\n",
    "\n",
    "        self.detector_normalised = self._detector['normalised']\n",
    "        self.detector_confidences = self._detector['confidences']\n",
    "\n",
    "        self.matcher_warp = self._matcher['warp'] # only one you will need\n",
    "        self.matcher_certainty = self._matcher['certainty']\n",
    "\n",
    "        self.filter_normalised = self._filter['normalised']\n",
    "        self.filter_confidences = self._filter['confidences']\n",
    "\n",
    "        self.cropped_image_reference_coords = self._matches['crop/reference_coords']\n",
    "        self.cropped_image_target_coords = self._matches['crop/target_coords']\n",
    "    \n",
    "    def close(self):\n",
    "        self._file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: cam0\n",
      "Group: cam0/detector\n",
      "Group: cam0/detector/confidences\n",
      "Group: cam0/detector/normalised\n",
      "Group: cam0/filter\n",
      "Group: cam0/filter/confidences\n",
      "Group: cam0/filter/normalised\n",
      "Group: cam0/matcher\n",
      "Group: cam0/matcher/certainty\n",
      "Group: cam0/matcher/warp\n",
      "Group: cam0/matches\n",
      "Group: cam0/matches/crop\n",
      "Group: cam0/matches/crop/reference_coords\n",
      "Group: cam0/matches/crop/target_coords\n",
      "Group: cam0/rotationssss\n",
      "Group: cam1\n",
      "Group: cam1/detector\n",
      "Group: cam1/detector/confidences\n",
      "Group: cam1/detector/normalised\n",
      "Group: cam1/filter\n",
      "Group: cam1/filter/confidences\n",
      "Group: cam1/filter/normalised\n",
      "Group: cam1/matcher\n",
      "Group: cam1/matcher/certainty\n",
      "Group: cam1/matcher/warp\n",
      "Group: cam1/matches\n",
      "Group: cam1/matches/crop\n",
      "Group: cam1/matches/crop/reference_coords\n",
      "Group: cam1/matches/crop/target_coords\n",
      "Group: cam1/rotationssss\n",
      "Group: cam2\n",
      "Group: cam2/detector\n",
      "Group: cam2/detector/confidences\n",
      "Group: cam2/detector/normalised\n",
      "Group: cam2/filter\n",
      "Group: cam2/filter/confidences\n",
      "Group: cam2/filter/normalised\n",
      "Group: cam2/matcher\n",
      "Group: cam2/matcher/certainty\n",
      "Group: cam2/matcher/warp\n",
      "Group: cam2/matches\n",
      "Group: cam2/matches/crop\n",
      "Group: cam2/matches/crop/reference_coords\n",
      "Group: cam2/matches/crop/target_coords\n",
      "Group: cam2/rotationssss\n",
      "Group: cam3\n",
      "Group: cam3/detector\n",
      "Group: cam3/detector/confidences\n",
      "Group: cam3/detector/normalised\n",
      "Group: cam3/filter\n",
      "Group: cam3/filter/confidences\n",
      "Group: cam3/filter/normalised\n",
      "Group: cam3/matcher\n",
      "Group: cam3/matcher/certainty\n",
      "Group: cam3/matcher/warp\n",
      "Group: cam3/matches\n",
      "Group: cam3/matches/crop\n",
      "Group: cam3/matches/crop/reference_coords\n",
      "Group: cam3/matches/crop/target_coords\n",
      "Group: cam3/rotationssss\n"
     ]
    }
   ],
   "source": [
    "f = StatsReader()\n",
    "print_hdf5_structure(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kd_pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
